#!/usr/bin/env python3
"""
===============================================================================
Arabic NLP for Real Estate Documents: Main Orchestrator Script
===============================================================================
This script provides a command-line interface (CLI) to manage the pipeline for:

1. Data Preprocessing:
    - Cleans and prepares Arabic real estate documents.
    - Tokenization, diacritic removal, and text normalization.

2. Model Training:
    - Trains models for text classification, NER, or summarization.
    - Supports popular frameworks like TensorFlow, PyTorch, and AraBERT.

3. Inference:
    - Performs NLP tasks on new real estate documents.
    - Generates classifications, extracted entities, or summaries.

4. Evaluation:
    - Computes evaluation metrics like precision, recall, and F1-score.

Example Commands:
    python main.py preprocess --input data/raw/real_estate_docs.txt --output data/processed/cleaned_docs.csv
    python main.py train --task classification --model bert
    python main.py inference --task ner --model_path models/ner_model.h5 --input_path data/processed/cleaned_docs.csv --output_path data/results/ner_results.csv
    python main.py evaluate --task classification --model_path models/text_classification_model.pkl --metrics precision recall f1

Repository Structure Assumption:
    Arabic-NLP-for-Real-Estate-Documents/
    ├── data/
    ├── models/
    ├── notebooks/
    ├── src/
    ├── tests/
    ├── docs/
    ├── animations/
    ├── .gitignore
    ├── LICENSE
    ├── README.txt
    ├── requirements.txt
    └── main.py
 
"""

import argparse
import logging
from src.preprocess import preprocess_arabic_text
from src.train import train_text_classification, train_ner, train_summarization
from src.inference import perform_inference
from src.evaluate import evaluate_classification

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

def main():
    """
    Main CLI for the Arabic NLP pipeline, orchestrating preprocessing, training,
    inference, and evaluation.
    """
    parser = argparse.ArgumentParser(
        prog="Arabic-NLP-for-Real-Estate-Documents",
        description="Command-line interface for Arabic NLP tasks on real estate documents."
    )

    subparsers = parser.add_subparsers(
        title="Commands",
        description="Available tasks",
        dest="command",
        required=True
    )

    # Preprocessing subcommand
    preprocess_parser = subparsers.add_parser("preprocess", help="Preprocess Arabic text data.")
    preprocess_parser.add_argument("--input", required=True, help="Path to the raw input file.")
    preprocess_parser.add_argument("--output", required=True, help="Path to save the cleaned output file.")

    # Training subcommand
    train_parser = subparsers.add_parser("train", help="Train an NLP model.")
    train_parser.add_argument("--task", choices=["classification", "ner", "summarization"], required=True, help="Task type.")
    train_parser.add_argument("--model", required=True, help="Model type (e.g., bert, lstm, transformer).")

    # Inference subcommand
    inference_parser = subparsers.add_parser("inference", help="Perform inference on new data.")
    inference_parser.add_argument("--task", choices=["classification", "ner", "summarization"], required=True, help="Task type.")
    inference_parser.add_argument("--model_path", required=True, help="Path to the trained model file.")
    inference_parser.add_argument("--input_path", required=True, help="Path to the input data file.")
    inference_parser.add_argument("--output_path", required=True, help="Path to save inference results.")

    # Evaluation subcommand
    evaluate_parser = subparsers.add_parser("evaluate", help="Evaluate a trained model.")
    evaluate_parser.add_argument("--task", choices=["classification", "ner", "summarization"], required=True, help="Task type.")
    evaluate_parser.add_argument("--model_path", required=True, help="Path to the trained model file.")
    evaluate_parser.add_argument("--metrics", nargs="+", choices=["precision", "recall", "f1"], required=True, help="Metrics to compute.")

    # Parse arguments
    args = parser.parse_args()

    # Dispatch commands
    if args.command == "preprocess":
        preprocess_arabic_text(args.input, args.output)
    elif args.command == "train":
        if args.task == "classification":
            train_text_classification()
        elif args.task == "ner":
            train_ner()
        elif args.task == "summarization":
            train_summarization()
    elif args.command == "inference":
        perform_inference(args.task, args.model_path, args.input_path, args.output_path)
    elif args.command == "evaluate":
        evaluate_classification()  # Extend to support other tasks as needed
    else:
        logging.error("Unknown command.")
        parser.print_help()


if __name__ == "__main__":
    main()
